{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lillianphyo/mlopszoomcamp2024/blob/master/mlops_zoomcamp_hw1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_RI8Khki9j-"
   },
   "source": [
    "# Forecasting AWS Cloud Expenses: Utilizing Billing Data for Price Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VvhtGMZQjJH3"
   },
   "source": [
    "Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "3028NeLIjORc",
    "outputId": "df318632-50a4-4249-c67f-17587f28c5b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.63.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas matplotlib seaborn keras tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_yPhvJyCfV_"
   },
   "source": [
    "Q1  Downloading the data <br>\n",
    "\n",
    "We'll use the same NYC taxi dataset, but instead of \"Green Taxi Trip Records\", we'll use \"Yellow Taxi Trip Records\".\n",
    "\n",
    "Download the data for January and February 2023.\n",
    "\n",
    "Read the data for January. How many columns are there?\n",
    "\n",
    "16\n",
    "17\n",
    "18\n",
    "19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-VPEb9Sa-ku6",
    "outputId": "81a26320-f3d4-4486-c943-2ae5cae80a13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0               2  2023-01-01 00:32:10   2023-01-01 00:40:36              1.0   \n",
      "1               2  2023-01-01 00:55:08   2023-01-01 01:01:27              1.0   \n",
      "2               2  2023-01-01 00:25:04   2023-01-01 00:37:49              1.0   \n",
      "3               1  2023-01-01 00:03:48   2023-01-01 00:13:25              0.0   \n",
      "4               2  2023-01-01 00:10:29   2023-01-01 00:21:19              1.0   \n",
      "...           ...                  ...                   ...              ...   \n",
      "3066761         2  2023-01-31 23:58:34   2023-02-01 00:12:33              NaN   \n",
      "3066762         2  2023-01-31 23:31:09   2023-01-31 23:50:36              NaN   \n",
      "3066763         2  2023-01-31 23:01:05   2023-01-31 23:25:36              NaN   \n",
      "3066764         2  2023-01-31 23:40:00   2023-01-31 23:53:00              NaN   \n",
      "3066765         2  2023-01-31 23:07:32   2023-01-31 23:21:56              NaN   \n",
      "\n",
      "         trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
      "0                 0.97         1.0                  N           161   \n",
      "1                 1.10         1.0                  N            43   \n",
      "2                 2.51         1.0                  N            48   \n",
      "3                 1.90         1.0                  N           138   \n",
      "4                 1.43         1.0                  N           107   \n",
      "...                ...         ...                ...           ...   \n",
      "3066761           3.05         NaN               None           107   \n",
      "3066762           5.80         NaN               None           112   \n",
      "3066763           4.67         NaN               None           114   \n",
      "3066764           3.15         NaN               None           230   \n",
      "3066765           2.85         NaN               None           262   \n",
      "\n",
      "         DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
      "0                 141             2         9.30   1.00      0.5        0.00   \n",
      "1                 237             1         7.90   1.00      0.5        4.00   \n",
      "2                 238             1        14.90   1.00      0.5       15.00   \n",
      "3                   7             1        12.10   7.25      0.5        0.00   \n",
      "4                  79             1        11.40   1.00      0.5        3.28   \n",
      "...               ...           ...          ...    ...      ...         ...   \n",
      "3066761            48             0        15.80   0.00      0.5        3.96   \n",
      "3066762            75             0        22.43   0.00      0.5        2.64   \n",
      "3066763           239             0        17.61   0.00      0.5        5.32   \n",
      "3066764            79             0        18.15   0.00      0.5        4.43   \n",
      "3066765           143             0        15.97   0.00      0.5        2.00   \n",
      "\n",
      "         tolls_amount  improvement_surcharge  total_amount  \\\n",
      "0                 0.0                    1.0         14.30   \n",
      "1                 0.0                    1.0         16.90   \n",
      "2                 0.0                    1.0         34.90   \n",
      "3                 0.0                    1.0         20.85   \n",
      "4                 0.0                    1.0         19.68   \n",
      "...               ...                    ...           ...   \n",
      "3066761           0.0                    1.0         23.76   \n",
      "3066762           0.0                    1.0         29.07   \n",
      "3066763           0.0                    1.0         26.93   \n",
      "3066764           0.0                    1.0         26.58   \n",
      "3066765           0.0                    1.0         21.97   \n",
      "\n",
      "         congestion_surcharge  airport_fee  \n",
      "0                         2.5         0.00  \n",
      "1                         2.5         0.00  \n",
      "2                         2.5         0.00  \n",
      "3                         0.0         1.25  \n",
      "4                         2.5         0.00  \n",
      "...                       ...          ...  \n",
      "3066761                   NaN          NaN  \n",
      "3066762                   NaN          NaN  \n",
      "3066763                   NaN          NaN  \n",
      "3066764                   NaN          NaN  \n",
      "3066765                   NaN          NaN  \n",
      "\n",
      "[3066766 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Replace 'your_file.parquet' with the path to your Parquet file\n",
    "file_path = '/content/yellow_tripdata_2023-01.parquet'\n",
    "\n",
    "try:\n",
    "    # Reading Parquet file into a DataFrame\n",
    "    df = pd.read_parquet(file_path)\n",
    "    print(df)\n",
    "except Exception as e:\n",
    "    print(f\"Error reading Parquet file: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAbUUzlNCnGh"
   },
   "source": [
    "Q2 Computing duration <br>\n",
    "Now let's compute the duration variable. It should contain the duration of a ride in minutes.\n",
    "\n",
    "What's the standard deviation of the trips duration in January?\n",
    "\n",
    "32.59\n",
    "42.59\n",
    "52.59\n",
    "62.59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ryvu_UReABwc",
    "outputId": "08f15428-1a7c-4af0-fc51-10675970eca7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard deviation of the trip durations in January 2023 is: 42.59 minutes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL for the January 2023 Yellow Taxi Trip Records (you need to update this with the actual URL)\n",
    "url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet'\n",
    "\n",
    "# Read the dataset from the URL\n",
    "try:\n",
    "    df = pd.read_parquet(url)\n",
    "\n",
    "    # Ensure the pickup and dropoff datetime columns are in datetime format\n",
    "    df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "    df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "\n",
    "    # Compute the trip duration in minutes\n",
    "    df['trip_duration'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "\n",
    "    # Calculate the standard deviation of the trip durations\n",
    "    std_dev = df['trip_duration'].std()\n",
    "    print(f\"The standard deviation of the trip durations in January 2023 is: {std_dev:.2f} minutes\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uk-dBrn6CssX"
   },
   "source": [
    "Q3 Dropping outliers <br>\n",
    "Next, we need to check the distribution of the duration variable. There are some outliers. Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "What fraction of the records left after you dropped the outliers?\n",
    "\n",
    "90%\n",
    "92%\n",
    "95%\n",
    "98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DVkgNmwuAzRM",
    "outputId": "d49dc55f-921d-4c94-c2fe-a30b2dec5b9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction of records remaining after removing outliers is: 98.12%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL for the January 2023 Yellow Taxi Trip Records (you need to update this with the actual URL)\n",
    "url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet'\n",
    "\n",
    "# Read the dataset from the URL\n",
    "try:\n",
    "    df = pd.read_parquet(url)\n",
    "\n",
    "    # Ensure the pickup and dropoff datetime columns are in datetime format\n",
    "    df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "    df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "\n",
    "    # Compute the trip duration in minutes\n",
    "    df['trip_duration'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "\n",
    "    # Calculate the original number of records\n",
    "    original_count = len(df)\n",
    "\n",
    "    # Filter records to keep durations between 1 and 60 minutes (inclusive)\n",
    "    filtered_df = df[(df['trip_duration'] >= 1) & (df['trip_duration'] <= 60)]\n",
    "\n",
    "    # Calculate the filtered number of records\n",
    "    filtered_count = len(filtered_df)\n",
    "\n",
    "    # Calculate the fraction of records remaining\n",
    "    fraction_remaining = (filtered_count / original_count) * 100\n",
    "    print(f\"The fraction of records remaining after removing outliers is: {fraction_remaining:.2f}%\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPQpCU5MCzAU"
   },
   "source": [
    "Q4 One-hot encoding <br>\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model.\n",
    "\n",
    "Turn the dataframe into a list of dictionaries (remember to re-cast the ids to strings - otherwise it will label encode them)\n",
    "Fit a dictionary vectorizer\n",
    "Get a feature matrix from it\n",
    "What's the dimensionality of this matrix (number of columns)?\n",
    "\n",
    "2\n",
    "155\n",
    "345\n",
    "515\n",
    "715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tdvZg1oLA_Ba",
    "outputId": "19456229-ee1e-4564-8f76-df2077f0d23e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensionality of the feature matrix is: 515 columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# URL for the January 2023 Yellow Taxi Trip Records (you need to update this with the actual URL)\n",
    "url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet'\n",
    "\n",
    "# Read the dataset from the URL\n",
    "try:\n",
    "    df = pd.read_parquet(url)\n",
    "\n",
    "    # Ensure the pickup and dropoff datetime columns are in datetime format\n",
    "    df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "    df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "\n",
    "    # Compute the trip duration in minutes\n",
    "    df['trip_duration'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "\n",
    "    # Filter records to keep durations between 1 and 60 minutes (inclusive)\n",
    "    df = df[(df['trip_duration'] >= 1) & (df['trip_duration'] <= 60)]\n",
    "\n",
    "    # Convert location IDs to strings\n",
    "    df['PULocationID'] = df['PULocationID'].astype(str)\n",
    "    df['DOLocationID'] = df['DOLocationID'].astype(str)\n",
    "\n",
    "    # Create a list of dictionaries\n",
    "    data_dicts = df[['PULocationID', 'DOLocationID']].to_dict(orient='records')\n",
    "\n",
    "    # Fit a dictionary vectorizer\n",
    "    vec = DictVectorizer()\n",
    "    feature_matrix = vec.fit_transform(data_dicts)\n",
    "\n",
    "    # Get the dimensionality of the feature matrix\n",
    "    num_columns = feature_matrix.shape[1]\n",
    "    print(f\"The dimensionality of the feature matrix is: {num_columns} columns\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJVyY1REC3XF"
   },
   "source": [
    "\n",
    "Q5 Training a model <br>\n",
    "Now let's use the feature matrix from the previous step to train a model.\n",
    "\n",
    "Train a plain linear regression model with default parameters, where duration is the response variable\n",
    "Calculate the RMSE of the model on the training data\n",
    "What's the RMSE on train?\n",
    "\n",
    "3.64\n",
    "7.64\n",
    "11.64\n",
    "16.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hnNDD2jVBVPa",
    "outputId": "af20f1f8-2e79-4e15-fdd9-68db8398d268"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE on the training data is: 7.65\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# URL for the January 2023 Yellow Taxi Trip Records (you need to update this with the actual URL)\n",
    "url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet'\n",
    "\n",
    "# Read the dataset from the URL\n",
    "try:\n",
    "    df = pd.read_parquet(url)\n",
    "\n",
    "    # Ensure the pickup and dropoff datetime columns are in datetime format\n",
    "    df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "    df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "\n",
    "    # Compute the trip duration in minutes\n",
    "    df['trip_duration'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "\n",
    "    # Filter records to keep durations between 1 and 60 minutes (inclusive)\n",
    "    df = df[(df['trip_duration'] >= 1) & (df['trip_duration'] <= 60)]\n",
    "\n",
    "    # Convert location IDs to strings\n",
    "    df['PULocationID'] = df['PULocationID'].astype(str)\n",
    "    df['DOLocationID'] = df['DOLocationID'].astype(str)\n",
    "\n",
    "    # Create a list of dictionaries\n",
    "    data_dicts = df[['PULocationID', 'DOLocationID']].to_dict(orient='records')\n",
    "\n",
    "    # Fit a dictionary vectorizer\n",
    "    vec = DictVectorizer()\n",
    "    X = vec.fit_transform(data_dicts)\n",
    "\n",
    "    # Get the response variable\n",
    "    y = df['trip_duration'].values\n",
    "\n",
    "    # Train a linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Predict on the training data\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Calculate the RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    print(f\"The RMSE on the training data is: {rmse:.2f}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3c93CV8C8ZE"
   },
   "source": [
    "Q6 Evaluating the model <br>\n",
    "Now let's apply this model to the validation dataset (February 2023).\n",
    "\n",
    "What's the RMSE on validation?\n",
    "\n",
    "3.81\n",
    "7.81\n",
    "11.81\n",
    "16.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XJ68Bid5B6xi",
    "outputId": "3a78d64d-683b-423b-e953-c760e8048793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE on the validation data is: 7.81\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Function to preprocess and filter the dataset\n",
    "def preprocess_data(url):\n",
    "    df = pd.read_parquet(url)\n",
    "    df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "    df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "    df['trip_duration'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "    df = df[(df['trip_duration'] >= 1) & (df['trip_duration'] <= 60)]\n",
    "    df['PULocationID'] = df['PULocationID'].astype(str)\n",
    "    df['DOLocationID'] = df['DOLocationID'].astype(str)\n",
    "    return df\n",
    "\n",
    "# URL for the January 2023 Yellow Taxi Trip Records\n",
    "january_url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet'\n",
    "\n",
    "# Preprocess January data\n",
    "df_january = preprocess_data(january_url)\n",
    "\n",
    "# Create a list of dictionaries and fit the dictionary vectorizer\n",
    "data_dicts_january = df_january[['PULocationID', 'DOLocationID']].to_dict(orient='records')\n",
    "vec = DictVectorizer()\n",
    "X_january = vec.fit_transform(data_dicts_january)\n",
    "y_january = df_january['trip_duration'].values\n",
    "\n",
    "# Train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_january, y_january)\n",
    "\n",
    "# URL for the February 2023 Yellow Taxi Trip Records\n",
    "february_url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet'\n",
    "\n",
    "# Preprocess February data\n",
    "df_february = preprocess_data(february_url)\n",
    "\n",
    "# Transform February data using the same dictionary vectorizer\n",
    "data_dicts_february = df_february[['PULocationID', 'DOLocationID']].to_dict(orient='records')\n",
    "X_february = vec.transform(data_dicts_february)\n",
    "y_february = df_february['trip_duration'].values\n",
    "\n",
    "# Predict on the validation data\n",
    "y_pred_february = model.predict(X_february)\n",
    "\n",
    "# Calculate the RMSE on the validation data\n",
    "rmse_february = np.sqrt(mean_squared_error(y_february, y_pred_february))\n",
    "print(f\"The RMSE on the validation data is: {rmse_february:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOF8bQDGUQBR3JhJpL1EyS6",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
